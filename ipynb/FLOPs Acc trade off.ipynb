{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laughing-great",
   "metadata": {},
   "source": [
    "The notebook provide analysis of teh acc/FLOPs trade-off.\n",
    "Set `data` to choose different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "cmap = sns.color_palette()\n",
    "sns.set_palette(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = './fig/flops_acc_curve'\n",
    "if not os.path.exists(cache_path):\n",
    "    os.makedirs(cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-seattle",
   "metadata": {},
   "source": [
    "**NOTE**: Set `data` to choose different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Set data here\n",
    "data = 'Digits'\n",
    "\n",
    "if data == 'Digits':\n",
    "    sweep_dict = {\n",
    "        'FedAvg': \"jyhong/SplitMix_release/sweeps/8g8s7kp4\",\n",
    "        'SHeteroFL': \"jyhong/SplitMix_release/sweeps/0lh7d73x\",\n",
    "        'SplitMix': \"jyhong/SplitMix_release/sweeps/3wr7bsxb\",\n",
    "    }\n",
    "elif data == 'DomainNet':\n",
    "    sweep_dict = {\n",
    "        'FedAvg': \"jyhong/SplitMix_release/sweeps/y489wn02\",\n",
    "        'SHeteroFL': \"jyhong/SplitMix_release/sweeps/shs7yw8p\",\n",
    "        'SplitMix': \"jyhong/SplitMix_release/sweeps/2kxrau5h\",\n",
    "    }\n",
    "elif data == 'Cifar10_cniid':\n",
    "    sweep_dict = {\n",
    "        'FedAvg': \"jyhong/SplitMix_release/sweeps/6ua8jh9x\",\n",
    "        'SHeteroFL': \"jyhong/SplitMix_release/sweeps/fvg0045z\",\n",
    "        'SplitMix': \"jyhong/SplitMix_release/sweeps/g71nb2yv\",\n",
    "    }\n",
    "else:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_config_summary(runs, config_keys, summary_keys):\n",
    "    df_dict = defaultdict(list)\n",
    "    for run in runs:\n",
    "        if run.state != 'finished':\n",
    "            print(\"WARN: run not finished yet\")\n",
    "        history_len = 0\n",
    "        missing_sum_key = []\n",
    "        for k in summary_keys:\n",
    "            if k in run.summary:\n",
    "                h = run.summary[k]\n",
    "                df_dict[k].append(h)\n",
    "            else:\n",
    "                missing_sum_key.append(k)\n",
    "                break\n",
    "        if len(missing_sum_key) > 0:\n",
    "            print(f\"missing key: {missing_sum_key}\")\n",
    "            continue\n",
    "        for k in config_keys:\n",
    "            df_dict[k].append(run.config[k])\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-extent",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'FedAvg'\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(sweep_dict[mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = fetch_config_summary(\n",
    "    sweep.runs,\n",
    "    config_keys = ['width_scale'], \n",
    "    summary_keys = ['avg test acc', 'GFLOPs', 'model size (MB)']\n",
    ")\n",
    "df = pd.DataFrame(df_dict)\n",
    "df['mode'] = mode\n",
    "df['width_scale'] = df['width_scale'] * 100\n",
    "df['width'] = df['width_scale']\n",
    "\n",
    "agg_df_dict[mode] = df  # [df['slim_ratio'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "# for slim_ratio, val_accs in zip(df_dict['slim_ratio'], df_dict['val_acc']):\n",
    "#     plt.plot(val_accs)\n",
    "sns.lineplot(data=df, x='width', y='avg test acc', marker='o')\n",
    "ax.set(xticks=df['width'].unique())\n",
    "# ax.set(xlim=(0, 150), ylim=(0.3, 0.9))\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-testament",
   "metadata": {},
   "source": [
    "## SHeteroFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'SHeteroFL'\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(sweep_dict[mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = fetch_config_summary(\n",
    "    sweep.runs,\n",
    "    config_keys = ['test_slim_ratio'], \n",
    "    summary_keys = ['avg test acc', 'GFLOPs', 'model size (MB)']\n",
    ")\n",
    "df = pd.DataFrame(df_dict)\n",
    "df['test_slim_ratio'] = df['test_slim_ratio'] * 100\n",
    "df['width'] = df['test_slim_ratio']\n",
    "\n",
    "df['mode'] = mode\n",
    "agg_df_dict[mode] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "# for slim_ratio, val_accs in zip(df_dict['slim_ratio'], df_dict['val_acc']):\n",
    "#     plt.plot(val_accs)\n",
    "sns.lineplot(data=df, x='test_slim_ratio', y='avg test acc', \n",
    "             marker='o')\n",
    "ax.set(xticks=df['test_slim_ratio'].unique())\n",
    "# ax.set(xlim=(0, 150), ylim=(0.3, 0.9))\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-scratch",
   "metadata": {},
   "source": [
    "## Split-Mix 0.125atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# for atom_slim_ratio in [0.125, 0.25]:\n",
    "for mode in ['SplitMix']:\n",
    "    print(f\"mode: {mode}\")\n",
    "    api = wandb.Api()\n",
    "    sweep = api.sweep(sweep_dict[mode])\n",
    "\n",
    "    df_dict = fetch_config_summary(\n",
    "        sweep.runs,\n",
    "        config_keys = ['test_slim_ratio', 'atom_slim_ratio'], \n",
    "        summary_keys = ['avg test acc', 'GFLOPs', 'model size (MB)']\n",
    "    )\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df['mode'] = mode\n",
    "    df['test_slim_ratio'] = df['test_slim_ratio'] * 100\n",
    "    df['width'] = df['test_slim_ratio']\n",
    "    dfs.append(df)\n",
    "    agg_df_dict[mode] = df\n",
    "    \n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "# for slim_ratio, val_accs in zip(df_dict['slim_ratio'], df_dict['val_acc']):\n",
    "#     plt.plot(val_accs)\n",
    "sns.lineplot(data=df, x='test_slim_ratio', y='avg test acc', marker='o')\n",
    "ax.set(xticks=df['test_slim_ratio'].unique())\n",
    "# ax.set(xlim=(0, 150), ylim=(0.3, 0.9))\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-invalid",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = pd.concat([v for k, v in agg_df_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = agg.reset_index()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "sns.lineplot(data=agg, x='width', y='avg test acc', marker='o', hue='mode')\n",
    "ax.set(xticks=df['test_slim_ratio'].unique(), ylabel='average test accuracy')\n",
    "# ax.set(xlim=(0, 150), ylim=(0.3, 0.9))\n",
    "ax.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# out_file = os.path.join(cache_path, f'digits_width_acc_curve.pdf')\n",
    "# print(f\"save fig => {out_file}\")\n",
    "# plt.savefig(out_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg = pd.concat([v for k, v in agg_df_dict.items()])\n",
    "agg = pd.concat([agg_df_dict[k] for k in ['FedAvg', \"SHeteroFL\", \"SplitMix\"]])\n",
    "\n",
    "agg['avg test acc'] = agg['avg test acc'] * 100\n",
    "agg['MFLOPs'] = agg['GFLOPs'] * 1e3\n",
    "\n",
    "agg = agg.drop(['test_slim_ratio', 'atom_slim_ratio', 'GFLOPs'],\n",
    "               axis=1).set_index(['mode', 'width']).unstack('mode')\n",
    "agg.columns = agg.columns.swaplevel(0,1)\n",
    "agg.sort_index(axis=1, level=0, inplace=True)\n",
    "# agg.reindex(columns = agg.columns.reindex(['avg test acc', 'MFLOPs', 'model size (MB)'], level = 1))\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg.to_latex(float_format=\"{:0.1f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-nancy",
   "metadata": {},
   "source": [
    "## Analysis of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg = pd.concat([v for k, v in agg_df_dict.items()])\n",
    "agg = pd.concat([agg_df_dict[k] for k in ['FedAvg', \"SHeteroFL\", \"SplitMix\"]])\n",
    "\n",
    "agg['avg test acc'] = agg['avg test acc'] * 100\n",
    "agg['MFLOPs'] = agg['GFLOPs'] * 1e3\n",
    "\n",
    "agg = agg.drop(['test_slim_ratio', 'atom_slim_ratio', 'GFLOPs', 'width_scale'], \n",
    "               axis=1).set_index(['mode', 'width']).unstack('mode')\n",
    "agg.columns = agg.columns.swaplevel(0,1)\n",
    "agg.sort_index(axis=1, level=0, inplace=True)\n",
    "# agg.reindex(columns = agg.columns.reindex(['avg test acc', 'MFLOPs', 'model size (MB)'], level = 1))\n",
    "agg = agg.stack('mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.reset_index().groupby(['mode', 'width']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_per_domain_dict = defaultdict(list)  # {'domains': [], 'params': [], 'mode': []}\n",
    "res_per_user_dict = defaultdict(list)\n",
    "if data == 'Digits':\n",
    "    domains = ['MNIST', 'SVHN', 'USPS', 'SynthDigits', 'MNIST_M']\n",
    "    pd_nuser = 10\n",
    "    batch_size = 32\n",
    "elif data == 'DomainNet':\n",
    "    domains = ['real',      'clipart',   'infograph', 'painting',  'quickdraw', 'sketch']\n",
    "    pd_nuser = 5\n",
    "    batch_size = 32\n",
    "elif 'Cifar10' in data:\n",
    "    domains = ['cifar10']\n",
    "    pd_nuser = 100\n",
    "    batch_size = 128\n",
    "n_domain = len(domains)\n",
    "n_user = pd_nuser * n_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = agg.reset_index()\n",
    "FedAvg_params = df_[df_['mode'] == 'FedAvg']['model size (MB)'].sum()\n",
    "param_per_domain_dict['domains'] += domains\n",
    "param_per_domain_dict['params'] += [1.]*len(domains)\n",
    "param_per_domain_dict['mode'] += ['FedAvg'] * len(domains)\n",
    "\n",
    "res_per_user_dict['mode'] += ['FedAvg'] * n_user\n",
    "res_per_user_dict['params/rnd'] += [df_[df_['mode'] == 'FedAvg']['model size (MB)'].min()] * n_user\n",
    "res_per_user_dict['MFLOPs/batch'] += [df_[df_['mode'] == 'FedAvg']['MFLOPs'].min()*3*batch_size] * n_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'SHeteroFL'\n",
    "\n",
    "df_ = agg.reset_index()\n",
    "widths = df_['width'].unique()\n",
    "max_widths = [widths[int((i*1./n_user)*len(widths))] for i in range(n_user)]\n",
    "user_domain = [int((i*1./n_user)*len(domains)) for i in range(n_user)]\n",
    "param_per_domain = [0 for _ in domains]\n",
    "param_per_user = [0 for _ in range(n_user)]\n",
    "flops_per_user = [0 for _ in range(n_user)]\n",
    "\n",
    "for u in range(n_user):\n",
    "    max_width = widths[int((u*1./n_user)*len(widths))]\n",
    "    domain = int((u*1./n_user)*len(domains))\n",
    "    param_per_domain[domain] += df_[(df_['mode'] == mode) & (max_width == df_['width'])]['model size (MB)'].values[0] / pd_nuser\n",
    "    # upload the max-width model\n",
    "    param_per_user[u] += df_[(df_['mode'] == mode) & (max_width == df_['width'])]['model size (MB)'].values[0]\n",
    "    # train FLOPs\n",
    "    for width in df_['width'].unique():\n",
    "        if width > max_width:\n",
    "            break\n",
    "        flops_per_user[u] += df_[(df_['mode'] == mode) & (width == df_['width'])]['MFLOPs'].values[0] * 3 * batch_size # gradient descent = backward (=2*forwad) + forward\n",
    "    \n",
    "param_per_domain = [ppd*1./df_[(df_['mode'] == mode)]['model size (MB)'].max() for ppd in param_per_domain]\n",
    "\n",
    "param_per_domain_dict['domains'] += domains\n",
    "param_per_domain_dict['params'] += param_per_domain\n",
    "param_per_domain_dict['mode'] += [mode] * len(domains)\n",
    "\n",
    "res_per_user_dict['mode'] += [mode] * n_user\n",
    "res_per_user_dict['params/rnd'] += param_per_user\n",
    "res_per_user_dict['MFLOPs/batch'] += flops_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'SplitMix'\n",
    "\n",
    "df_ = agg.reset_index()\n",
    "widths = df_['width'].unique()\n",
    "atom_width = np.min(widths)\n",
    "max_widths = [widths[int((i*1./n_user)*len(widths))] for i in range(n_user)]\n",
    "user_domain = [int((i*1./n_user)*len(domains)) for i in range(n_user)]\n",
    "param_per_domain = [0 for _ in domains]\n",
    "param_per_user = [0 for _ in range(n_user)]\n",
    "flops_per_user = [0 for _ in range(n_user)]\n",
    "\n",
    "for u in range(n_user):\n",
    "    max_width = widths[int((u*1./n_user)*len(widths))]\n",
    "    domain = int((u*1./n_user)*len(domains))\n",
    "    param_per_domain[domain] += df_[(df_['mode'] == mode)]['model size (MB)'].values[0] * max(max_widths)/df_['width'].min() / pd_nuser\n",
    "    # upload the max-width model\n",
    "    param_per_user[u] += df_[(df_['mode'] == mode)]['model size (MB)'].min() * int(max_width/atom_width)\n",
    "    # train FLOPs\n",
    "    for width in [df_['width'].min()]:\n",
    "        flops_per_user[u] += df_[(df_['mode'] == mode) & (width == df_['width'])]['MFLOPs'].values[0] * 3 * batch_size * int(max_width/atom_width) # gradient descent = backward (=2*forwad) + forward\n",
    "\n",
    "param_per_domain = [ppd*1./df_[(df_['mode'] == mode)]['model size (MB)'].max() for ppd in param_per_domain]\n",
    "    \n",
    "param_per_domain_dict['domains'] += domains\n",
    "param_per_domain_dict['params'] += param_per_domain\n",
    "param_per_domain_dict['mode'] += [mode] * len(domains)\n",
    "\n",
    "res_per_user_dict['mode'] += [mode] * n_user\n",
    "res_per_user_dict['params/rnd'] += param_per_user\n",
    "res_per_user_dict['MFLOPs/batch'] += flops_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(param_per_domain_dict)\n",
    "df['params'] = df['params'] * 100\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1, 1, figsize=(4,3))\n",
    "sns.barplot(data=df, x='domains', y='params', hue='mode')\n",
    "ax.set(title=\"percentage of trained parameters\", ylabel=\"\")\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.tight_layout()\n",
    "out_file = os.path.join(cache_path, f'{data}_domain_pct_param.pdf')\n",
    "print(f\"save fig => {out_file}\")\n",
    "plt.savefig(out_file)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res_per_user_dict)\n",
    "res_df['data'] = data\n",
    "display(res_df)\n",
    "\n",
    "out_file = os.path.join(cache_path, f'{data}_res_df.csv')\n",
    "print(f\"save df => {out_file}\")\n",
    "res_df.to_csv(out_file)\n",
    "\n",
    "group_df = res_df.groupby('mode')\n",
    "for stat in ['mean', 'std', 'max', 'min']:\n",
    "    print(stat)\n",
    "    eval(f'display(group_df.{stat}())')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
